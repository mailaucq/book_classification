{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network import CNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import verifyDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dataset = \"dataset_2\"\n",
    "length_cut = 1000\n",
    "random_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliar_path = 'auxiliar_folder/' + name_dataset   + '/'\n",
    "verifyDir(auxiliar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"df_train_\" + name_dataset + \"_\" + str(length_cut) + \"_\" + str(random_flag) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"df_val_\" + name_dataset + \"_\" + str(length_cut) + \"_\" + str(random_flag) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"df_test_\" + name_dataset + \"_\" + str(length_cut) + \"_\" + str(random_flag) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I saw through the open door way a lonely girl ...</td>\n",
       "      <td>hermanMelville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It is my father s fatal science No no Giovanni...</td>\n",
       "      <td>nathanielHawthorne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>left on the earth to show that it was all some...</td>\n",
       "      <td>bmBower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>blowing through the cracks of the floor It was...</td>\n",
       "      <td>andrewLang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>alive from fathoms Mr Couthouy Remarks on Cora...</td>\n",
       "      <td>charlesDarwin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  I saw through the open door way a lonely girl ...   \n",
       "1           1  It is my father s fatal science No no Giovanni...   \n",
       "2           2  left on the earth to show that it was all some...   \n",
       "3           3  blowing through the cracks of the floor It was...   \n",
       "4           4  alive from fathoms Mr Couthouy Remarks on Cora...   \n",
       "\n",
       "                label  \n",
       "0      hermanMelville  \n",
       "1  nathanielHawthorne  \n",
       "2             bmBower  \n",
       "3          andrewLang  \n",
       "4       charlesDarwin  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.text_processing import get_word_index, get_sequences, get_common_words, pre_process_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].apply(lambda t: pre_process_text(t, remove_stop_words=False, only_stop_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['text'] = df_test['text'].apply(lambda t: pre_process_text(t, remove_stop_words=False, only_stop_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['text'] = df_val['text'].apply(lambda t: pre_process_text(t, remove_stop_words=False, only_stop_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manager2 import graph2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in ./venv/lib/python3.8/site-packages (2.6.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph2vec_features(sequences):\n",
    "    measures = [\"dgr_n\", \"btw\", \"cc\", \"sp\", \"sp_std\", \"accs_h2\", \"accs_h3\"]\n",
    "    network_features = pd.DataFrame()\n",
    "    nets = []\n",
    "    for text in sequences:\n",
    "        obj = CNetwork(text, model=None, index_word=None, percentages=None, path=auxiliar_path)\n",
    "        network = obj.create_network()\n",
    "        nets.append(network)\n",
    "    network_features = np.array(graph2vec(\"\", \"linux\", nets))\n",
    "    print(network_features.shape)\n",
    "        #local_measure = obj.get_network_measures(network, word_features)\n",
    "        #a_series = pd.Series(local_measure)\n",
    "        #network_features = network_features.append(a_series, ignore_index=True)\n",
    "        #network_features = np.vstack([network_features, global_measure]) if len(network_features) > 0 else global_measure\n",
    "    return network_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_index, index_word = get_word_index(df_train[\"text\"])\n",
    "sequences = get_sequences(df_train[\"text\"], word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 123 - Edges: 418\n",
      "Nodes: 104 - Edges: 347\n",
      "Nodes: 86 - Edges: 281\n",
      "Nodes: 102 - Edges: 344\n",
      "Nodes: 81 - Edges: 262\n",
      "Nodes: 111 - Edges: 351\n",
      "Nodes: 103 - Edges: 386\n",
      "Nodes: 94 - Edges: 328\n",
      "Nodes: 107 - Edges: 407\n",
      "Nodes: 86 - Edges: 280\n",
      "Nodes: 120 - Edges: 412\n",
      "Nodes: 108 - Edges: 377\n",
      "Nodes: 107 - Edges: 386\n",
      "Nodes: 86 - Edges: 331\n",
      "Nodes: 99 - Edges: 342\n",
      "Nodes: 105 - Edges: 369\n",
      "Nodes: 114 - Edges: 411\n",
      "Nodes: 113 - Edges: 376\n",
      "Nodes: 103 - Edges: 347\n",
      "Nodes: 110 - Edges: 395\n",
      "Nodes: 101 - Edges: 363\n",
      "Nodes: 113 - Edges: 408\n",
      "Nodes: 117 - Edges: 408\n",
      "Nodes: 112 - Edges: 385\n",
      "Nodes: 95 - Edges: 292\n",
      "Nodes: 95 - Edges: 310\n",
      "Nodes: 110 - Edges: 361\n",
      "Nodes: 99 - Edges: 323\n",
      "Nodes: 88 - Edges: 297\n",
      "Nodes: 100 - Edges: 364\n",
      "Nodes: 107 - Edges: 371\n",
      "Nodes: 127 - Edges: 470\n",
      "Nodes: 102 - Edges: 395\n",
      "Nodes: 96 - Edges: 342\n",
      "Nodes: 100 - Edges: 331\n",
      "Nodes: 104 - Edges: 342\n",
      "Nodes: 102 - Edges: 309\n",
      "Nodes: 95 - Edges: 339\n",
      "Nodes: 90 - Edges: 278\n",
      "Nodes: 115 - Edges: 417\n",
      "Nodes: 93 - Edges: 330\n",
      "Nodes: 114 - Edges: 339\n",
      "Nodes: 109 - Edges: 387\n",
      "Nodes: 102 - Edges: 411\n",
      "Nodes: 91 - Edges: 369\n",
      "Nodes: 95 - Edges: 307\n",
      "Nodes: 90 - Edges: 332\n",
      "Nodes: 110 - Edges: 347\n",
      "Nodes: 107 - Edges: 345\n",
      "Nodes: 94 - Edges: 291\n",
      "Nodes: 108 - Edges: 389\n",
      "Nodes: 68 - Edges: 238\n",
      "Nodes: 109 - Edges: 388\n",
      "Nodes: 106 - Edges: 379\n",
      "Nodes: 96 - Edges: 315\n",
      "Nodes: 108 - Edges: 357\n",
      "Nodes: 102 - Edges: 333\n",
      "Nodes: 111 - Edges: 365\n",
      "Nodes: 80 - Edges: 267\n",
      "Nodes: 101 - Edges: 360\n",
      "Existe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature extraction started.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 8/60 [00:00<00:03, 16.77it/s]\r",
      "100%|██████████| 60/60 [00:00<00:00, 110.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization started.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph2vec\n",
      "(60, 513)\n"
     ]
    }
   ],
   "source": [
    "X_train = get_graph2vec_features(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 513)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 96 - Edges: 364\n",
      "Nodes: 88 - Edges: 317\n",
      "Nodes: 107 - Edges: 373\n",
      "Nodes: 119 - Edges: 386\n",
      "Nodes: 109 - Edges: 358\n",
      "Nodes: 110 - Edges: 393\n",
      "Nodes: 104 - Edges: 394\n",
      "Nodes: 100 - Edges: 287\n",
      "Nodes: 100 - Edges: 336\n",
      "Nodes: 107 - Edges: 361\n",
      "Nodes: 91 - Edges: 311\n",
      "Nodes: 110 - Edges: 377\n",
      "Nodes: 94 - Edges: 313\n",
      "Nodes: 108 - Edges: 397\n",
      "Nodes: 97 - Edges: 329\n",
      "Nodes: 89 - Edges: 291\n",
      "Nodes: 103 - Edges: 352\n",
      "Nodes: 119 - Edges: 390\n",
      "Nodes: 101 - Edges: 404\n",
      "Nodes: 120 - Edges: 397\n",
      "Existe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature extraction started.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 96.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization started.\n",
      "\n",
      "graph2vec\n",
      "(20, 513)\n"
     ]
    }
   ],
   "source": [
    "X_val = get_graph2vec_features(get_sequences(df_val[\"text\"], word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 513)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['whashingtonIrving', 'andrewLang', 'hgWells', 'henryJames', 'allanPoe', 'charlesDarwin', 'markTwain', 'hectorMunro', 'nathanielHawthorne', 'zaneGrey', 'arthurDoyle', 'horatioAlger', 'richardHarding', 'thomasHardy', 'janeAusten', 'charlesDickens', 'hermanMelville', 'pgWodehouse', 'bmBower', 'bramStoker']\n",
      "Total classes: 20\n",
      "Total entities for each class in train: 3\n"
     ]
    }
   ],
   "source": [
    "classes = list(df_train['label'])  ## or 'author'\n",
    "total_classes = list(set(df_train['label']))  ## or author\n",
    "print(\"Classes: {}\".format(total_classes))\n",
    "print(\"Total classes: {}\".format(len(total_classes)))\n",
    "number_books = (df_train[df_train['label'] == total_classes[0]]).shape[0]\n",
    "print(\"Total entities for each class in train: {}\".format(number_books))\n",
    "dict_categories = list(set(classes))\n",
    "dict_categories = {cat: index for index, cat in enumerate(dict_categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [dict_categories[y] for y in df_train[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = [dict_categories[y] for y in df_val[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.59596708e-02,  3.44870123e-03, ...,\n",
       "         9.90505051e-03,  3.99466557e-03, -3.47805396e-03],\n",
       "       [ 1.00000000e+00,  2.11192202e-02,  3.70291295e-03, ...,\n",
       "         1.30059281e-02,  4.45512636e-03, -5.13168564e-03],\n",
       "       [ 2.00000000e+00,  1.38613554e-02,  3.12729017e-03, ...,\n",
       "         7.50998734e-03,  2.59151892e-03, -2.30660802e-03],\n",
       "       ...,\n",
       "       [ 5.70000000e+01,  2.10642610e-02,  4.76927683e-03, ...,\n",
       "         1.33396070e-02,  5.44338208e-03, -5.34721278e-03],\n",
       "       [ 5.80000000e+01,  1.29139982e-02,  2.05798191e-03, ...,\n",
       "         7.33312825e-03,  4.12028795e-03, -2.72408593e-03],\n",
       "       [ 5.90000000e+01,  1.22972187e-02,  2.56084744e-03, ...,\n",
       "         8.34067352e-03,  3.59506370e-03, -2.86866492e-03]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 8,\n",
       " 18,\n",
       " 1,\n",
       " 5,\n",
       " 13,\n",
       " 13,\n",
       " 6,\n",
       " 14,\n",
       " 0,\n",
       " 17,\n",
       " 13,\n",
       " 1,\n",
       " 3,\n",
       " 19,\n",
       " 18,\n",
       " 11,\n",
       " 16,\n",
       " 6,\n",
       " 11,\n",
       " 1,\n",
       " 9,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 2,\n",
       " 19,\n",
       " 4,\n",
       " 0,\n",
       " 19,\n",
       " 8,\n",
       " 3,\n",
       " 14,\n",
       " 15,\n",
       " 10,\n",
       " 15,\n",
       " 7,\n",
       " 17,\n",
       " 0,\n",
       " 17,\n",
       " 7,\n",
       " 18,\n",
       " 11,\n",
       " 14,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 16,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 10,\n",
       " 4,\n",
       " 8,\n",
       " 10,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 15]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifierv2 import getClassifier, getClassMetrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  1.59596708e-02  3.44870123e-03 ...  9.90505051e-03\n",
      "   3.99466557e-03 -3.47805396e-03]\n",
      " [ 1.00000000e+00  2.11192202e-02  3.70291295e-03 ...  1.30059281e-02\n",
      "   4.45512636e-03 -5.13168564e-03]\n",
      " [ 2.00000000e+00  1.38613554e-02  3.12729017e-03 ...  7.50998734e-03\n",
      "   2.59151892e-03 -2.30660802e-03]\n",
      " ...\n",
      " [ 5.70000000e+01  2.10642610e-02  4.76927683e-03 ...  1.33396070e-02\n",
      "   5.44338208e-03 -5.34721278e-03]\n",
      " [ 5.80000000e+01  1.29139982e-02  2.05798191e-03 ...  7.33312825e-03\n",
      "   4.12028795e-03 -2.72408593e-03]\n",
      " [ 5.90000000e+01  1.22972187e-02  2.56084744e-03 ...  8.34067352e-03\n",
      "   3.59506370e-03 -2.86866492e-03]]\n",
      "[16, 8, 18, 1, 5, 13, 13, 6, 14, 0, 17, 13, 1, 3, 19, 18, 11, 16, 6, 11, 1, 9, 12, 12, 12, 2, 19, 4, 0, 19, 8, 3, 14, 15, 10, 15, 7, 17, 0, 17, 7, 18, 11, 14, 4, 6, 5, 16, 9, 7, 3, 5, 10, 4, 8, 10, 2, 9, 2, 15]\n",
      "[5, 0, 11, 15, 18, 4, 14, 12, 7, 3, 6, 10, 16, 1, 13, 2, 8, 9, 19, 17]\n",
      "[ 1  1  1  1 13 13 13 13  0  0  0  0  1  1  1  3  6 11 11  1]\n",
      "accuracy : 0.05\n",
      "micro f-measure 0.05000000000000001\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "predicted = knn_clf.predict(X_val)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(y_val)\n",
    "print(predicted)\n",
    "#print accuracy_score\n",
    "print(\"accuracy : \" + str(accuracy_score(y_val, predicted)))\n",
    "\n",
    "print(\"micro f-measure \" + str(f1_score(y_val, predicted, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  1.59596708e-02  3.44870123e-03 ...  9.90505051e-03\n",
      "   3.99466557e-03 -3.47805396e-03]\n",
      " [ 1.00000000e+00  2.11192202e-02  3.70291295e-03 ...  1.30059281e-02\n",
      "   4.45512636e-03 -5.13168564e-03]\n",
      " [ 2.00000000e+00  1.38613554e-02  3.12729017e-03 ...  7.50998734e-03\n",
      "   2.59151892e-03 -2.30660802e-03]\n",
      " ...\n",
      " [ 5.70000000e+01  2.10642610e-02  4.76927683e-03 ...  1.33396070e-02\n",
      "   5.44338208e-03 -5.34721278e-03]\n",
      " [ 5.80000000e+01  1.29139982e-02  2.05798191e-03 ...  7.33312825e-03\n",
      "   4.12028795e-03 -2.72408593e-03]\n",
      " [ 5.90000000e+01  1.22972187e-02  2.56084744e-03 ...  8.34067352e-03\n",
      "   3.59506370e-03 -2.86866492e-03]]\n",
      "[16, 8, 18, 1, 5, 13, 13, 6, 14, 0, 17, 13, 1, 3, 19, 18, 11, 16, 6, 11, 1, 9, 12, 12, 12, 2, 19, 4, 0, 19, 8, 3, 14, 15, 10, 15, 7, 17, 0, 17, 7, 18, 11, 14, 4, 6, 5, 16, 9, 7, 3, 5, 10, 4, 8, 10, 2, 9, 2, 15]\n",
      "[5, 0, 11, 15, 18, 4, 14, 12, 7, 3, 6, 10, 16, 1, 13, 2, 8, 9, 19, 17]\n",
      "[13 13 13 13 13 13 13 13 13 13 13 13  1  1  1  1  1  1  1  1]\n",
      "accuracy : 0.05\n",
      "micro f-measure 0.05000000000000001\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='linear', probability=True)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "predicted = svc.predict(X_val)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(y_val)\n",
    "print(predicted)\n",
    "#print accuracy_score\n",
    "print(\"accuracy : \" + str(accuracy_score(y_val, predicted)))\n",
    "\n",
    "print(\"micro f-measure \" + str(f1_score(y_val, predicted, average='micro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
